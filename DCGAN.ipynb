{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHDXAVwFLwGJkCjhwlOqWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kazuhiko-Miyata/DCGAN_MNIST_generate/blob/main/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DCGANの対応**\n",
        "DCGAN（Deep Convolutional Generative Adversarial Networks）は、生成器と識別器に畳み込みニューラルネットワークを利用した、オリジナルGANの発展版。\n",
        "\n",
        "DCGANはCNNのおかげで、オリジナルGANに比べて画像が鮮明になり、安定した学習が可能になった。DCGANの作成には試行錯誤を要し、作成の指針は論文によると次の通り。\n",
        "\n",
        "\n",
        "<br><br>\n",
        "1.   識別機にストライド２の畳み込み層、生成器にストライド２の転置畳み込み層を利用\n",
        "2.   全結合層は利用しない\n",
        "3.   出力層と生成器の入力層を除き、バッチ正規化を利用\n",
        "4.   生成器は活性化関数にReLUを利用し、出力層はtanh関数を利用\n",
        "5.   識別器はすべての活性化関数にLeaky ReLUを利用\n",
        "6.   本物画像を-1～1の値域で正規化\n",
        "\n",
        "<br><br>指針1.によると、識別器は畳み込み層を使用する。識別器の畳み込み層は、Aの3×3カーネルがストライド2で移動する。また、パティング1の場合は点線のように画像の周囲が外側へ1だけ広がる。結果、Bの5×5画像を畳み込み層に入力するとCの3×3画像を出力し、画像サイズが縮小する。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pbNgI3BAG4AU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1XfxGckrKO3hgcAlE_qghhGl4VeHl3HVg\" width=\"80%\">"
      ],
      "metadata": {
        "id": "W3O5bjNuY-XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成器に使用する転置畳み込み層もDの3×3カーネルがストライド２で移動する。またパディングして画像の周囲を外側へ１だけ広げる。結果Eの3×3画像を転置畳み込み層に入力するとFの5×5画像を出力し、画像サイズが拡大する。"
      ],
      "metadata": {
        "id": "1LuvWX2ndQRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1Ff5c_Q92lbPHNWBq-ilupYmHKYRi4O8n\" width=\"80%\">"
      ],
      "metadata": {
        "id": "_skSDU2xaoES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "指針４によると、生成器の出力層にtanh関数を使用する。tanh関数は-1～1の値域であるため、生成画像のが措置は-1～1になる。識別器は本物画像と生成画像の真贋を判定するため、が措置の値域をそろえる必要がある。そのため、指針6で本物画像のが画素値を-1～1の値域に変換する。\n",
        "\n",
        "<br><br>指針5によると、識別器の活性化関数にLeaky reLUを使用する。生成器は識別器を経由して、誤差を逆伝播する。そのため値がマイナスでも勾配消失しないLeaky ReLUを使用する。"
      ],
      "metadata": {
        "id": "8aei1mtFdnSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![tanh.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "69GT-JF8hfuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **生成器のネットワーク（白黒）画像**\n",
        "今回のDCGANおよび次の節のConditionalGANはデータセットMNISTを用いて数字画像を生成する。ストライド２つの転置畳み込み層で画像サイズを拡大する。生成器の活性化関数はReLUを使用するが、出力層だけは活性化関数にtanh関数を利用し、バッチ正規化を使用しない点に注意。"
      ],
      "metadata": {
        "id": "6npmMJ0ghqN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1YCvRvmuEBuoBpHN3cf7EYv-b2sRA6oQr\" width=\"40%\">"
      ],
      "metadata": {
        "id": "j9Mgs3toRJKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、生成器に入力するノイズ$z$を用意する。ノイズは1次元ベクトルだが、生成器はCNNのため、ノイズを畳み込み層が計算できるTensor（配列）に変換する必要がある。PyTorchの場合、畳み込みそうは4次元Tensorを入力する仕様。\n",
        "\n",
        "<br><br>**Tensorの形状=(バッチサイズ、チャンネル、高さ、幅)**\n",
        "\n",
        "<br><br>1画像の生成にしようするノイズベクトルの次元数は100、ネットワークにB個のノイズ$z$を一度に入力する場合、Tensorの形状は次のようになる。\n",
        "\n",
        "<br><br>**ノイズ$z$のTensorの形状=(B,100, 1, 1)**\n",
        "\n",
        "<br><br>生成機の中の転置畳み込み層は、ノイズのTensorを画像のTensorに変換する。結果、生成器はB個のサイズ２８×２８の画像を出力する。画像は白黒につきチャンネル数は１。\n",
        "<br>layer0の中には転置畳み込み層、バッチ正規化、ReLUの活性化関数がある。転置畳み込み層は画像サイズを拡大するので、layer0のTensorは（B、５１２、３、３）に変換される。続けてlayer1、layer2でもlayer0と同じ処理を実行し、Tensorは（B、１２８、１４、１４）になる。最後のlayer3は転置畳み込み層とTanhの構成で、支出力チャンネル数は白黒画像のため1になる。その結果、Tensorは（B、１、２８、２８）に変換され、サイズ２８×２８の白黒画像がB個ぶん生成できる。これで、バッチサイズB個の画像を生成できる。\n",
        "\n",
        "<br><br>**▽生成器GのクラスGenerator**\n",
        "\n",
        "```\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    生成器Gのクラス\n",
        "    \"\"\"\n",
        "    def __init__(self, nz=100, nch_g=128, nch=1):\n",
        "        \"\"\"\n",
        "        :param nz: 入力ベクトルの次元\n",
        "        :param nch_g: 最終層の入力チャンネル数\n",
        "        :param nch: 出力画像のチャンネル数\n",
        "        \"\"\"\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # ニューラルネットワークの構造を定義する\n",
        "        self.layer = nn.ModuleDict({\n",
        "            \"layer0\":nn.Sequential(\n",
        "                nn.ConvTranspose2d(nz, nch_g * 4, 3, 1, 0),\n",
        "                                                # 転置畳み込み\n",
        "                nn.BatchNorm2d(nch_g * 4),   # バッチノーマライゼーション\n",
        "                nn.ReLU()                      # ReLU\n",
        "            ),    # (B, nz, 1, 1) -> (B, nch_g*4, 3, 3)\n",
        "            \"layer1\":nn.Sequential(\n",
        "                nn.ConvTranspose2d(nch_g * 4, nch_g *2, 3, 2, 0),\n",
        "                nn.BatchNorm2d(nch_g * 2),\n",
        "                nn.ReLU()\n",
        "            ),   # (B, nch_g*4, 3, 3) -> (B, nch_g*2, 7, 7)\n",
        "            \"layer2\":nn.Sequential(\n",
        "                nn.ConvTranspose2d(nch_g * 2, nch_g, 4, 2, 1),\n",
        "                nn.BatchNorm2d(nch_g),\n",
        "                nn.ReLU()\n",
        "            ),   # (B, nch_g*2, 7, 7) -> (B, nch_g, 14, 14)\n",
        "            \"layer3\":nn.Sequential(\n",
        "                nn.ConvTranspose2d(nch_g, nch, 4, 2, 1),\n",
        "                nn.Tanh()\n",
        "            ),   # (B, nch_g, 14, 14) -> (B, nch, 28, 28)\n",
        "        })\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        順方向の演算\n",
        "        :param z: 入力ベクトル\n",
        "        :return: 生成画像\n",
        "        \"\"\"\n",
        "        for layer in self.layer.values():  # self.layerの各層で演算を行う\n",
        "            z = layer(z)\n",
        "        return z\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jyBSxBmIVk99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **識別器のネットワーク（白黒画像）**\n",
        "識別器は画像の真贋を識別するネットワーク。識別器は本物と生成どちらかの画像が入力され、本物である確立を出力する。識別器はストライド２の畳み込み層で画像を縮小する。活性化関数にLeaky ReLUを利用し、入力層と出力そうはバッチ正規化を使用しないことに注意。"
      ],
      "metadata": {
        "id": "EhuF5IqHYgR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1QAA9YGBpRE3rka9Kck7tcBGfMOxWy_WA\" width=\"40%\">"
      ],
      "metadata": {
        "id": "b-cJNT_SY73-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "識別器はB個の本物画像または生成画像を識別する。画像は白黒のためチャンネル数は１、画像サイズは２８×２８のため、Tensorは（B、１、２８、２８）になる。layer0の中には畳み込み層、Leaky ReLUがあり、Tensorは（B、１２８、１４、１４）に変換される。続くlayer1とlayer２の中には畳み込み層、バッチ正規化、Leaky ReLUがあり、画像サイズは段階的に小さくなる。layer3は畳み込み層とSigmoid関数で、B個の識別信号（B、１、１、１）のTensorに変換される。識別器の最後にaqueezeメソッドがあり、不要な次元は削除され、識別器はB個の識別信号（スカラー）を出力する。\n",
        "\n",
        "<br><br>**▽識別器DのクラスDiscriminator**\n",
        "\n",
        "\n",
        "```\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    識別器Dのクラス\n",
        "    \"\"\"\n",
        "    def __init__(self, nch=1, nch_d=128):\n",
        "        \"\"\"\n",
        "        :param nch: 入力画像のチャンネル数\n",
        "        :param nch_d: 先頭層の出力チャンネル数\n",
        "        \"\"\"\n",
        "        # ニューラルネットワークの構造を定義する\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.layer = nn.ModuleDict({\n",
        "            \"layer0\":nn.Sequential(\n",
        "                nn.Conv2d(nch, nch_d, 4, 2, 1), # 畳み込み\n",
        "                nn.LeakyReLU(negative_slope=0.2),   # Leaky ReLU関数\n",
        "            ),    # (B, nch, 28, 28) -> (B, nch_d, 14, 14)\n",
        "            \"layer1\":nn.Sequential(\n",
        "                nn.Conv2d(nch_d, nch_d * 2, 4, 2, 1),\n",
        "                nn.BatchNorm2d(nch_d * 2),\n",
        "                nn.LeakyReLU(negative_slope=0.2)\n",
        "            ),   # (B,nch_d, 14, 14) -> (B, nch_d*2, 7, 7)\n",
        "            \"layer2\":nn.Sequential(\n",
        "                nn.Conv2d(nch_d * 2, nch_d * 4, 3, 2, 0),\n",
        "                nn.BatchNorm2d(nch_d * 4),\n",
        "                nn.LeakyReLU(negative_slope=0.2)\n",
        "            ),   # (B, nch_d*2, 7, 7) -> (B, nch_d*4, 3, 3)\n",
        "            \"layer3\":nn.Sequential(\n",
        "                nn.Conv2d(nch_d * 4, 1, 3, 1, 0),\n",
        "                nn.Sigmoid(). # Sigmoid関数\n",
        "            ),   # (B, nch_d*4, 3, 3) -> (B, 1, 1,1)\n",
        "        })\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順方向の演算\n",
        "        :param x: 本物画像あるいは生成画像\n",
        "        :return: 識別信号\n",
        "        \"\"\"\n",
        "        for layer in self.layers.values():  # self.layersの各層で演算を行う\n",
        "            x = layer(x)\n",
        "        return x.squeeze() # Tensorの形状を（B）に変更して戻り値とする         \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "1vYqBhioaXLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **識別器の損失関数**\n",
        "GANの損失関数は以下の式になる。損失関数は識別器と生成器の学習に使用する。\n",
        "\n",
        "<br><br>$$\n",
        "\\min_{G} \\max_{D}L(D,G)=\\mathbb{E}_{x\\sim{pdata(x)}}[\\log{D(x)}+\\mathbb{E}_{z\\sim{p_z(z)}}[\\log(1-D(G(z)))]\n",
        "$$\n",
        "\n",
        "<br><br>損失関数$L(D,G)$は識別器Dが最大化、生成器Gが最小化する。GANは識別器と生成器で交互に学習するため、損失関数を識別器の損失関数$L(D)$と生成器の損失関数$L(G)$の2つに分けて考える。なお、損失関数$L(D)$は損失関数$L(D,G)$の符号を逆にして、識別器Dの最小値問題と考える。\n",
        "\n",
        "<br><br>$$\n",
        "L(D)=-\\mathbb{E}_{x\\sim{pdata(x)}}[\\log D(x)]-\\mathbb{E}_{z\\sim{pz}(z)}[\\log(1-D(G(z)))]\n",
        "$$\n",
        "\n",
        "<br><br>識別器Dは本物画像と生成画像の２種類の入力があり、損失関数$L(D)$は本物画像の損失と生成画像の損失の合計となる。本物画像の入力時は識別信号$D(x)$を出力し、生成画像の入力時は識別信号$D(G(z))$を出力する。\n",
        "<br>第１項目は本物画像の損失でデータ分布$_{pdata}(x)$から画像$x$を取り出し、識別器の識別信号が$D(x)=1$のときの損失は0になる。第２項はノイズの確立分布$_{p_z}(x)$からノイズ$z$と取り出し、識別器の識別信号が$D(G(z))=0$のとき損失は0になる。つまり損失関数$L(D)$は、識別器が本物画像と生成画像を正しく分類した時に損失が0になり、誤分類した時に損失が発生する。\n",
        "<br>識別器Dの損失関数は識別器の2クラス分類と考えると、バイナリークロスエントロピーで定式化できる、バイナリークロスエントロピーは負の尤度関数を用いて最小値を計算する。正解ラベルは$y=1$、偽物$y=0$の２値になる。\n",
        "\n",
        "<br><br>$$\n",
        "J^D=-y\\log D(x)-(1-y) \\log(1-D(G(z)))\n",
        "$$\n",
        "\n",
        "<br><br>本物画像を識別器に入力するとき、正解ラベルは$y=1$となり、第１項は識別信号$D(x)$の誤差計算に使用する。また、生成画像を入力するとき、正解ラベルは$y=0$となり、第２項は識別信号$D(G(z))$の誤差計算に利用する。識別信号$D$と$D(G(z))$は識別器の最終層のSigmoid関数があるため0〜1の値域になる。"
      ],
      "metadata": {
        "id": "b2UyZ9QKhXMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **生成機の損失関数**\n",
        "損失関数$L(G)$は損失関数$L(D,G)$の最小値を計算する。\n",
        "\n",
        "<br><br>$$\n",
        "\\min_{G} \\max_{D}L(D,G)=\\mathbb{E}_{x\\sim{pdata(x)}}[\\log D(x)]+\\mathbb{E}_{z\\sim{p_z(z)}}[\\log(1-D(G(z)))]\n",
        "$$\n",
        "\n",
        "<br><br>生成器Gはノイズの確立分布$_{p_z}(z)$からノイズ$z$を取り出すため、損失関数$L(G)$は損失関数$L(D, G)$の第２項だけ使用する。第１項はノイズに対して定数になり、学習する際にお勾配は0なので無視する。\n",
        "\n",
        "<br><br>$$\n",
        "L(G)=\\mathbb{E}_{z\\sim_{p_z(z)}}[\\log(1-D(G(z)))]\n",
        "$$\n",
        "\n",
        "<br><br>生成器は、識別器を本物だとだますことができたら、識別信号$D(G(z))=1$となる。このとき、損失関数$L(G)$はマイナス無限大になり、損失は最小化する。逆にだますことができなかったら、識別信号$D(G(z))=0$となり、損失関数は0で最大化する。\n",
        "<br>しかし損失関数$L(G)$はオリジナルGANに説明がある通り、$D(G(z))=0$付近の勾配が小さく、生成機の学習が進まないという問題がある。そこで、損失関数$L(G)$を次のように書き換え、勾配消失を防ぐ。\n",
        "\n",
        "<br><br>$$\n",
        "L(G)=-\\mathbb{E}_{z\\sim{p_z}(z)}[\\log(1-D(G(z)))]\n",
        "$$\n",
        "\n",
        "<br><br>書き換えにより、$D(G(z))=0$付近に大きな勾配が発生し、生成機の学習が可能になる。また、$D(G(z))=1$で損失は0になる。"
      ],
      "metadata": {
        "id": "LfO6uUVUrOj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1o2X-cRoLnV2RLVRqiwPK9cHycb2zkC3t\" width=\"60%\">"
      ],
      "metadata": {
        "id": "2cFw5V68vU3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成器mぽ識別器と同様にバイナリークロスエントロピーの損失関数で定式化できる。ただし、生成器と識別器の符号は逆になる。\n",
        "\n",
        "<br><br>$$\n",
        "J^G=-J^D\n",
        "$$\n",
        "\n",
        "<br>$$\n",
        "J^G=y\\log D(x)+(1-y)\\log(1-D(G(z)))\n",
        "$$\n",
        "\n",
        "<br><br>バイナリークロスエントロピーでは、正解は$y=1$と$y=0$の２値だが、生成機は$y=0$の生成画像のクラスだけを使用し、第２項が残る。\n",
        "\n",
        "<br><br>$$\n",
        "J^G=\\log(1-D(G(z)))\n",
        "$$\n",
        "\n",
        "<br>さらに$L(G)$と同じく、損失関数$J^G$は次の用に書き直せる。\n",
        "\n",
        "<br><br>$$\n",
        "J^G=-\\log D(G(z))\n",
        "$$\n",
        "\n",
        "<br><br>この式はバイナリークロスエントロピーの$J^G=-y\\log D(G(z))$の$y=1$の指揮と同じで、正解ラベルは$y=0$ではなく$y=1$と考える。また識別信号$D(G(z))=1$、つまり生成器が識別器を本物だとだましたとき、損失関数$J^G$は0になり最小化する。"
      ],
      "metadata": {
        "id": "Fru9fLM6vqR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DCGANの実装**\n",
        "生成器のネットワークを定義する。printでネットワークの中を確認できる。生成器は転置叩き込みそう、バッチ正規化、ReLUで構成される。出力層はTanh()で-1～1の値域を取る。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 生成器G ランダムベクトルから生成画像を生成する\n",
        "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
        "netG.apply(weights_init)  # weights_init関数で初期化\n",
        "print(netG)\n",
        "```\n",
        "\n",
        "<br><br>次に識別器のネットワークを定義する。識別器は畳み込み層、バッチ正規化、Leaky ReLUで構成される。出力層はSigmoid（）で、出力値は0～1の値域になる。\n",
        "\n",
        "\n",
        "```\n",
        "# 識別器D 画像が本物画像か生成画像化を識別する\n",
        "netD = Discriminator(nch_d=nch_d).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)\n",
        "```\n",
        "\n",
        "<br><br>MNISTは0～255のが措置を敦賀、torchvisionに格納されているMNISTのが措置は0～1に正規化されている。このが措置を平均0.5/分散0.5で正規化し、-1（黒）～1（白）の値域に変換する。この変換は、生成器の出力値が-1～1の値域なので、本物画像の画素値を生成画像の画素値-1～1にそろえるための対応。dataloaderは1回の学習のイテレーションで取り出すデータ数を設定する。\n",
        "<br>バッチサイズの数を指定するbatch_sizeに50を設定し、1回の学習で50個の画像を取り出す。\n",
        "\n",
        "\n",
        "```\n",
        "# MNISTの訓練データセットを読み込む\n",
        "dataset = dset.MNIST(root'./mnist_root', download=True,\n",
        "train=True, transform=transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5,),(0.5)) ]))\n",
        "# 訓練データをセットしたデータローダーを作成する\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=int(workers))\n",
        "```\n",
        "\n",
        "<br><br>損失関数は、識別器Dの識別信号と正解ラベルが入力になる。識別器の出力層にSigmoid関数を設定したので、損失関数criterionはSigmoid関数を省いたクラスnn.BCELoss()を使用する。\n",
        "<br>1エポックごとに確認用の画像を生成できるよう、固定用のノイズベクトルを50個作成する。なお、ノイズは一様分布よりも標準正規分布からサンプリングする。\n",
        "\n",
        "\n",
        "```\n",
        "criterion = nn.BCELoss()   # バイナリークロスエントロピー\n",
        "\n",
        "# 生成器のエポックごとの画像生成に使用する確認用の固定ノイズ\n",
        "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "\n",
        "# optimizerのセットアップ\n",
        "optimizerD = optim.Adam(netD.para,eters(), ly=lr, betas=(deta1, 0.999),\n",
        "              weight_decay=1e-5) # 識別器D用\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999),\n",
        "              weight_decay=1e-5) # 生成器G用\n",
        "```\n",
        "識別器Dは本物画像と生成画像のそれぞれについて本物か偽物かを識別するので、識別器の損失は本物画像の損失と生成画像の損失の合計になる。\n",
        "\n",
        "<br><br>$$\n",
        "J^D=-y\\log D(x)-(1-y)\\log(1-D(G(z)))\n",
        "$$\n",
        "\n",
        "<br><br>本物画像の損失を求めるため、本物画像real_imagesを識別器netDに入力し、識別信号outputと正解ラベルreal_targetの1（本物）を比較し、errD_realを計算する。生成画像については、バッチサイズぶんのノイズnoiseを生成器netGに入力してfake_imageを生成し、これを識別器netDに入力して、識別信号outputを計算する。続けて、生成画像の損失を求めるため、識別信号outputと正解ラベルfake_targetの0（偽物）を比較し、errD_fakeを計算する。識別器の損失はerrD_realとerrD_fakeの合計になるので、損失を逆伝播して、識別器DのパラメータをoptimizerD.step()で更新する。このとき、生成器のパラメータは更新しないことに注意。\n",
        "\n",
        "\n",
        "```\n",
        "# 学習のループ\n",
        "for epoch in range(n_epoch):\n",
        "    for itr, data in enumerate(dataloader):\n",
        "        real_image = data[0].to(device)\n",
        "        samole_size = real_image.size(0)\n",
        "\n",
        "        # 標準正規分布からノイズを生成\n",
        "        noise = torch.randn(sample_size, nz, 1, 1, device=device)\n",
        "        # 本物画像に対する識別信号の目標値[1]\n",
        "        real_target = torch.full((sample_size,), 1., device=device)\n",
        "        # 生成画像に対する識別信号の目標値[0]\n",
        "        fake_target = torch.full((sample_size,), 0., device=device)\n",
        "\n",
        "        ##################################\n",
        "        # 識別器Dの更新\n",
        "        ##################################\n",
        "        netD.zero_grad()   # 勾配の初期化\n",
        "\n",
        "        output = netD(real_image) # 識別器Dで本物画像に対する識別信号を出力\n",
        "        errD_real = criterion(output, real_target) # 本物画像に対する識別信号の損失値\n",
        "        D_x = output.mean().item() # 本物画像の識別信号の平均\n",
        "\n",
        "        fake_image = netG(noise) # 生成器Gでノイズから生成画像を生成\n",
        "\n",
        "        output = netD(fake_image.detach()) # 識別器Dで生成画像に対する識別信号を出力\n",
        "        errD_fake = criterion(output, fake_target) # 生成画像に対する識別信号の損失値\n",
        "        D_G_z1 = output.mean().item.() # 生成画像の識別信号の平均\n",
        "\n",
        "        errD = errD_real + errD_fake # 識別器Dの全体の損失\n",
        "        errD.backwqard() # 誤差逆伝播\n",
        "        optimizerD.step() # Dのパラメータを更新\n",
        "```\n",
        "\n",
        "<br><br>生成器Gは生成画像の損失だけ必要なので、生成器の損失は次の式になる。\n",
        "\n",
        "<br><br>$$\n",
        "J^G=-\\log D(G(z))\n",
        "$$\n",
        "\n",
        "<br><br>この時の識別器Dは直前のパラメータ更新optimizerD.step()で少し学習が進んでいく。今回は識別器のパラメータを固定して、生成器のパラメータを更新する。\n",
        "<br>識別器netDにfake_imageを入力して、識別信号outputを計算する。生成画像の損失を求めるため、sikibetusinngou\n",
        "outputと本物の正解ラブrreal_targetの１を比較し、errGを計算する。損失errGを誤差逆伝播して、生成器GのパラメータをoptimizerG.step()で更新する。\n",
        "\n",
        "\n",
        "```\n",
        "    ##########################\n",
        "    # 生成器Gの更新\n",
        "    ##########################\n",
        "    netG.zero_grad()  # 勾配の初期化\n",
        "\n",
        "    output = netD(fake_image)  # 更新した識別器Dで改めて生成画像に対する識別信号を出力\n",
        "    errG = criterion(output, real_target)  # 生成器Gの損失値。Dに生成画像を本物画像と誤認させたいため目標値は[1]\n",
        "    errG.backward()  # 誤差逆伝播\n",
        "    D_G_z2 = output.mean().item()  # 更新した識別器による生成画像の識別信号の平均\n",
        "\n",
        "    optimizerG.step()  # Gのパラメータ更新\n",
        "```\n",
        "\n",
        "<br><br>ログはdisplay_intervalの間隔で表示して、1エポックごとに生成画像を保存する。生成画像は1エポックごとの学習状況がわかるよう、学習ループの外で事前に作成した固定ノイズを利用する。\n",
        "<br>ログにはLoss_D、Loss_Gに加えて、D(x)、識別器$D(G(z))$、生成器の$D(G(z))$の3つが表示される。$D(x)$、識別器の$D(G(z))$は識別器Dに使用する識別信号の平均値で、Loss_DはD(x)が1、識別器のD(G(z))が0に近いほど低下する。一方Loss_Gは生成器のD(G(z))が1に近いほど、低下する。\n",
        "\n",
        "\n",
        "```\n",
        "    if itr % display_interval == 0:\n",
        "        print('[{}/{}][{}/{}] Loss D:{:.3f} Loss_G:{:.3f} D(x):{:.3f} D(G(z)):{:.3f}/{:.3f}\n",
        "            .format(epoch + 1, n_epoch,\n",
        "                itr +1, len(dataloader),\n",
        "                errD.item(), errG.item(), D_x, D_G_z1,\n",
        "        D_G_z2))\n",
        "\n",
        "    if epoch == 0 and itr == 0:   # 初回に本物画像を保存する\n",
        "        vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
        "        normalize=True, nrow=8)\n",
        "\n",
        "    ##########################\n",
        "     # 確認用画像の生成\n",
        "    ##########################\n",
        "    fale_image = netG(fixed_noise) # 1エポック終了後とに確認用の生成画像を生成する\n",
        "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch +1),\n",
        "        normalize=True, nrow=8)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0X7M0gBvb3lw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "識別器の識別信号$D(x)$は0.8前後で振動し、識別器の$D(G(z))$を示す「/」前は0.2前後で振動している。生成器の$D(G(z))$を示す「/」の後は識別器のパラメータ更新に伴い、識別器の$D(G(z))$より0に近い値になっていることがわかる。逆に、次イテレーションの識別器の$D(G(z))$は、生成器のパラメータ更新に伴い、生成器の$D(G(z))$より1に近づいていることがわかる。\n",
        "<br>最後に、本物画像と生成画像の比較をする。VAEの生成画像は全体的にぼやけていたが、GANの生成画像は本物画像と見分けがつかないほど鮮明になる。"
      ],
      "metadata": {
        "id": "NS6l0fLWjTP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torchsummary"
      ],
      "metadata": {
        "id": "waGrwbhEjyXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定\n",
        "workers = 2\n",
        "batch_size = 50\n",
        "nz = 100\n",
        "nch_g = 128\n",
        "nch_d = 128\n",
        "n_epoch = 10\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "outf = './result_3_2-DCGAN'\n",
        "display_interval = 600\n",
        "\n",
        "# 保存先ディレクトリを作成\n",
        "try:\n",
        "    os.makedirs(outf, exist_ok=True)\n",
        "except OSError as error:\n",
        "    print(error)\n",
        "    pass\n",
        "\n",
        "# 乱数のシードを固定\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azL5a0UQlRB9",
        "outputId": "6673f789-cd29-4df9-8191-8841570f300b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a2f5db03f50>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNISTのデータセットを読み込む\n",
        "dataset = dset.MNIST(root='./mnist_root', download=True, train=True,\n",
        "                     transform=transforms.Compose([\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.5,), (0.5))]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JGATfeznAYG",
        "outputId": "4b589b3e-9f0c-45e8-f89b-3bb21e13168b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_root/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 168744236.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_root/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_root/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_root/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 53599864.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_root/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_root/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_root/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 42157216.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_root/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_root/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_root/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 23091550.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist_root/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_root/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像配列の確認\n",
        "dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW__l7Sknnf0",
        "outputId": "26db100e-2a80-44bc-9dc9-7b5d41c14baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像の値域の確認\n",
        "dataset[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffh0W5oPsz0Y",
        "outputId": "8750d321-de44-4ab1-cc2a-e9d4160e346b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
              "          -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
              "           1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
              "           0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
              "           0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
              "          -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
              "          -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
              "          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
              "          -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
              "           0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
              "           0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
              "           0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
              "           0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
              "           0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
              "           0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
              "          -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
              "           0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
              "           0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データをセットしたデータローダーを作成する\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=int(workers))\n",
        "\n",
        "# 学習に使用するデバイスを得る\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh2Jt5yBs9FM",
        "outputId": "7dcf5210-b0d5-41b6-9e1c-19a8c357581b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "      \"\"\"\n",
        "      生成器のクラス\n",
        "      \"\"\"\n",
        "      def __init__(self, nz=100, nch_g=128, nch=1):\n",
        "          \"\"\"\n",
        "          :param nz: 入力ベクトルｚの次元\n",
        "          :param nch_g: 最終層の入力チャンネル数\n",
        "          :param nch: 出力画像のチャネル数\n",
        "          \"\"\"\n",
        "          super(Generator, self).__init__()\n",
        "\n",
        "          # ニューラルネットワークの構造を定義する\n",
        "          self.layers = nn.ModuleDict({\n",
        "            'layer0':nn.Sequential(\n",
        "                nn.ConvTranspose2d(nz, nch_g * 4, 3, 1, 0),\n",
        "                nn.BatchNorm2d(nch_g *4),\n",
        "                nn.ReLU()\n",
        "            ), # (B, nz, 1, 1) -> (B, nch_g*4, 3, 3)\n",
        "            \"layer1\": nn.Sequential(\n",
        "                nn.ConvTranspose2d(nch_g * 4, nch_g * 2, 3, 2, 0),\n",
        "                nn.BatchNorm2d(nch_g* 2),\n",
        "                nn.ReLU()\n",
        "            ), # (B, nch_g*4, 3, 3) -> (B, nch_g*2, 7, 7)\n",
        "            \"layer2\": nn.Sequential(\n",
        "                nn.ConvTranspose2d(nch_g * 2, nch_g, 4, 2, 1),\n",
        "                nn.ReLU()\n",
        "            ),  # (B, nch_g*2, 7, 7) -> (B, nch_g, 14, 14)\n",
        "            \"layer3\":nn.Sequential(\n",
        "                nn.ConvTranspose2d(nch_g, nch, 4, 2, 1),\n",
        "                nn.Tanh()\n",
        "            )  # (B, nch_g, 14, 14) -> (B, nch, 28, 28)\n",
        "          })\n",
        "\n",
        "      def forward(self, z):\n",
        "          \"\"\"\n",
        "          順方向の演算\n",
        "          :param z: 入力ベクトル\n",
        "          :return: 生成画像\n",
        "          \"\"\"\n",
        "          for layer in self.layers.values(): # self.layersの各層で演算を行う\n",
        "              z = layer(z)\n",
        "          return z\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "      \"\"\"\n",
        "      識別器Dのクラス\n",
        "      \"\"\"\n",
        "      def __init__(self, nch=1, nch_d=128):\n",
        "            \"\"\"\n",
        "            :param nch: 入力画像のチャネル数\n",
        "            :param nch_d: 先頭層の出力チャネル\n",
        "            \"\"\"\n",
        "            super(Discriminator, self).__init__()\n",
        "\n",
        "            # ニューラルネットワークの構造を定義する\n",
        "            self.layers = nn.ModuleDict({\n",
        "                \"layer0\":nn.Sequential(\n",
        "                      nn.Conv2d(nch, nch_d, 4, 2, 1),   # 畳み込み\n",
        "                      nn.LeakyReLU(negative_slope=0.2)  # leaky ReLU関数\n",
        "                ), # (B, nch, 28, 28) -> (B, nch_d, 14, 14)\n",
        "                \"layer1\":nn.Sequential(\n",
        "                      nn.Conv2d(nch_d, nch_d * 2, 4, 2, 1),\n",
        "                      nn.BatchNorm2d(nch_d * 2),\n",
        "                      nn.LeakyReLU(negative_slope=0.2)\n",
        "                ), # (B, nch_d, 14, 14) -> (B, nch_d*2, 7, 7)\n",
        "                \"layer2\":nn.Sequential(\n",
        "                      nn.Conv2d(nch_d * 2, nch_d * 4, 3, 2, 0),\n",
        "                      nn.BatchNorm2d(nch_d * 4),\n",
        "                      nn.LeakyReLU(negative_slope=0.2)\n",
        "                ),  # (B, nch_d*2, 7, 7) -> (B, nch_d*4, 3, 3)\n",
        "                \"layer3\":nn.Sequential(\n",
        "                      nn.Conv2d(nch_d * 4, 1, 3, 1, 0),\n",
        "                      nn.Sigmoid() # Sigmoid関数\n",
        "                )  # (B, nch_d*4, 3, 3) -> (B, 1, 1, 1)\n",
        "            })\n",
        "      def forward(self, x):\n",
        "            \"\"\"\n",
        "            順方向の演算\n",
        "            :param x: 本物画像あるい￥は生成画像\n",
        "            :return: 識別信号\n",
        "            \"\"\"\n",
        "            for layer in self.layers.values(): # self.layersの各層で演算を行う\n",
        "               x = layer(x)\n",
        "            return x.squeeze()  # Tensorの形状を(B)に変更して戻り値とする\n",
        "\n",
        "def weights_init(m):\n",
        "      \"\"\"\n",
        "      ニューラルネットワークの重みを初期化する。作成したインスタンスに対しapplyメソッドで適用する\n",
        "   　 :param m: ニューラルネットワークを構成する層\n",
        "      \"\"\"\n",
        "      classname = m.__class__.__name__\n",
        "      if classname.find(\"Conv\") != -1:    # 畳み込み層の場合\n",
        "          m.weight.data.normal_(0.0, 0.02)\n",
        "          m.bias.data.fill_(0)\n",
        "      elif classname.find(\"Linear\") != -1: # 全結合層の場合\n",
        "          m.weight.data.normal_(0.0, 0.02)\n",
        "          m.bias.data.fill_(0)\n",
        "      elif classname.find(\"BatchNorm\") != -1: # バッチノーマライゼーションの場合\n",
        "          m.weight.data.normal_(1.0, 0.02)\n",
        "          m.bias.data.fill_(0)\n",
        "\n",
        "# 生成器G　ランダムベクトルから生成画像を作成する\n",
        "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
        "netG.apply(weights_init)  # weights_init関数で初期化\n",
        "print(netG)\n",
        "\n",
        "# 生成器GのTensor形状\n",
        "torchsummary.summary(netG, (100, 1, 1))\n",
        "\n",
        "# 識別器D 画像が本物画像か生成画像化を識別する\n",
        "netD = Discriminator(nch_d=nch_d).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)\n",
        "\n",
        "# 識別器DのTensor形状\n",
        "torchsummary.summary(netD, (1, 28, 28))\n",
        "\n",
        "# 学習\n",
        "criterion = nn.BCELoss() # バイナリークロスエントロピー（Sigmoid関数無し）\n",
        "\n",
        "# 生成器のエポックごとの画像生成に使用する確認用の固定ノイズ\n",
        "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "\n",
        "# オプティマイザ−のセットアップ\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5) # 識別器D用\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5) # 生成器G用\n",
        "\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "D_x_out = []\n",
        "D_G_z1_out = []\n",
        "\n",
        "#学習のループ\n",
        "for epoch in range(n_epoch):\n",
        "      for itr, data in enumerate(dataloader):\n",
        "          real_image = data[0].to(device) # 本物画像\n",
        "          sample_size = real_image.size(0) # 画像枚数\n",
        "\n",
        "          # 標準正規分布からノイズを生成\n",
        "          noise = torch.randn(sample_size, nz, 1, 1, device=device)\n",
        "          # 本物画像に対する識別信号の目標値「1」\n",
        "          real_target = torch.full((sample_size,), 1., device=device)\n",
        "          # 生成画像に対する識別信号の目標値「0」\n",
        "          fake_target = torch.full((sample_size,), 0., device=device)\n",
        "\n",
        "          ############################\n",
        "          # 識別器Dの更新\n",
        "          ############################\n",
        "          netD.zero_grad() # 勾配の初期化\n",
        "\n",
        "          output = netD(real_image)  # 識別器Dで本物画像に対する識別信号を出力\n",
        "          errD_real = criterion(output, real_target) # 本物画像に対する識別信号の損失値\n",
        "          D_x = output.mean().item()  # 本物画像の識別信号の平均\n",
        "\n",
        "          fake_image = netG(noise)  # 生成器Gでノイズから生成画像を生成\n",
        "\n",
        "          output = netD(fake_image.detach())  # 識別器Dで本物画像に対する識別信号を出力\n",
        "          errD_fake = criterion(output, fake_target)  # 生成画像に対する識別信号の損失値\n",
        "          D_G_z1 = output.mean().item()  # 生成画像の識別信号の平均\n",
        "\n",
        "          errD = errD_real + errD_fake  # 識別器Dの全体の損失\n",
        "          errD.backward()  # 誤差逆伝播\n",
        "          optimizerD.step()  # Dのパラメーターを更新\n",
        "\n",
        "          ############################\n",
        "          # 生成器Gの更新\n",
        "          ###########################\n",
        "          netG.zero_grad()  # 勾配の初期化\n",
        "\n",
        "          output = netD(fake_image)  # 更新した識別器Dで改めて生成画像に対する識別信号を出力\n",
        "          errG = criterion(output, real_target)  # 生成器Gの損失値。Dに生成画像を本物画像と誤認させたいため目標値は「1」\n",
        "          errG.backward()  # 誤差逆伝播\n",
        "          D_G_z2 = output.mean().item()  # 更新した識別器Dによる生成画像の識別信号の平均\n",
        "\n",
        "          optimizerG.step()  # Gのパラメータを更新\n",
        "\n",
        "          if itr % display_interval ==0:\n",
        "                print(\"[{}/{}][{}/{}] Loss_D:{:.3f} Loss_G:{:.3f} D(x):{:.3f} D(G(z)):{:.3f}/{:.3f}\"\n",
        "                      .format(epoch + 1, n_epoch,\n",
        "                              itr + 1, len(dataloader),\n",
        "                              errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "          if epoch == 0 and itr == 0:  #　初回に本物画像を保存する\n",
        "              vutils.save_image(real_image, \"{}/real_samples.png\".format(outf),\n",
        "                                normalize=True, nrow=10)\n",
        "\n",
        "          # ログ出力用データの保存\n",
        "          D_losses.append(errD.item())\n",
        "          G_losses.append(errG.item())\n",
        "          D_x_out.append(D_x)\n",
        "          D_G_z1_out.append(D_G_z1)\n",
        "\n",
        "      ############################\n",
        "      # 確認用画像の生成\n",
        "      ############################\n",
        "      fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の生成画像を生成する\n",
        "      vutils.save_image(fake_image.detach(), \"{}/fake_samples_epoch_{:03d}.png\".format(outf, epoch + 1),\n",
        "                        normalize=True, nrow=10)\n",
        "\n",
        "      ############################\n",
        "      # モデルの保存\n",
        "      ############################\n",
        "      if (epoch + 1) % 10 == 0:  # 10エポックごとにモデルを保存する\n",
        "          torch.save(netG.state_dict(), \"{}/netG_epoch_{}.pth\".format(outf, epoch + 1))\n",
        "          torch.save(netD.state_dict(), \"{}/netD_epoch_{}.pth\".format(outf, epoch + 1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMn4wcfHxYsU",
        "outputId": "80b7d65e-cfd7-4b6a-d699-2d2d9d44a41d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing DCGAN.py\n"
          ]
        }
      ]
    }
  ]
}